<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_14-ea) on Sat Jun 19 12:25:20 PDT 2010 -->
<TITLE>
org.apache.hadoop.hbase.mapreduce (HBase 0.20.5 API)
</TITLE>

<META NAME="date" CONTENT="2010-06-19">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="org.apache.hadoop.hbase.mapreduce (HBase 0.20.5 API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Package</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-use.html"><FONT CLASS="NavBarFont1"><B>Use</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/hadoop/hbase/mapred/package-summary.html"><B>PREV PACKAGE</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/hadoop/hbase/master/package-summary.html"><B>NEXT PACKAGE</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/hadoop/hbase/mapreduce/package-summary.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="package-summary.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<H2>
Package org.apache.hadoop.hbase.mapreduce
</H2>
Provides HBase <a href="http://wiki.apache.org/hadoop/HadoopMapReduce">MapReduce</a>
Input/OutputFormats, a table indexing MapReduce job, and utility
<P>
<B>See:</B>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="#package_description"><B>Description</B></A>
<P>

<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Class Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/BuildTableIndex.html" title="class in org.apache.hadoop.hbase.mapreduce">BuildTableIndex</A></B></TD>
<TD>Example table column indexing class.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/Driver.html" title="class in org.apache.hadoop.hbase.mapreduce">Driver</A></B></TD>
<TD>Driver for hbase mapreduce jobs.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/Export.html" title="class in org.apache.hadoop.hbase.mapreduce">Export</A></B></TD>
<TD>Export an HBase table.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/GroupingTableMapper.html" title="class in org.apache.hadoop.hbase.mapreduce">GroupingTableMapper</A></B></TD>
<TD>Extract grouping columns from input record.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce">HFileOutputFormat</A></B></TD>
<TD>Writes HFiles.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/HRegionPartitioner.html" title="class in org.apache.hadoop.hbase.mapreduce">HRegionPartitioner&lt;KEY,VALUE&gt;</A></B></TD>
<TD>This is used to partition the output keys into groups of keys.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IdentityTableMapper.html" title="class in org.apache.hadoop.hbase.mapreduce">IdentityTableMapper</A></B></TD>
<TD>Pass the given key and record as-is to the reduce phase.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IdentityTableReducer.html" title="class in org.apache.hadoop.hbase.mapreduce">IdentityTableReducer</A></B></TD>
<TD>Convenience class that simply writes all values (which must be 
 <A HREF="../../../../../org/apache/hadoop/hbase/client/Put.html" title="class in org.apache.hadoop.hbase.client"><CODE>Put</CODE></A> or 
 <A HREF="../../../../../org/apache/hadoop/hbase/client/Delete.html" title="class in org.apache.hadoop.hbase.client"><CODE>Delete</CODE></A> instances)
 passed to it out to the configured HBase table.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/Import.html" title="class in org.apache.hadoop.hbase.mapreduce">Import</A></B></TD>
<TD>Import data written by <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/Export.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>Export</CODE></A>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IndexConfiguration.html" title="class in org.apache.hadoop.hbase.mapreduce">IndexConfiguration</A></B></TD>
<TD>Configuration parameters for building a Lucene index.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IndexConfiguration.ColumnConf.html" title="class in org.apache.hadoop.hbase.mapreduce">IndexConfiguration.ColumnConf</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IndexOutputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce">IndexOutputFormat</A></B></TD>
<TD>Create a local index, unwrap Lucene documents created by reduce, add them to
 the index, and copy the index to the destination.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IndexRecordWriter.html" title="class in org.apache.hadoop.hbase.mapreduce">IndexRecordWriter</A></B></TD>
<TD>Writes the records into a Lucene index writer.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IndexTableReducer.html" title="class in org.apache.hadoop.hbase.mapreduce">IndexTableReducer</A></B></TD>
<TD>Construct a Lucene document per row, which is consumed by IndexOutputFormat
 to build a Lucene index</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/KeyValueSortReducer.html" title="class in org.apache.hadoop.hbase.mapreduce">KeyValueSortReducer</A></B></TD>
<TD>Emits sorted KeyValues.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/LuceneDocumentWrapper.html" title="class in org.apache.hadoop.hbase.mapreduce">LuceneDocumentWrapper</A></B></TD>
<TD>A utility class used to pass a lucene document from reduce to OutputFormat.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/RowCounter.html" title="class in org.apache.hadoop.hbase.mapreduce">RowCounter</A></B></TD>
<TD>A job with a just a map phase to count rows.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableInputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce">TableInputFormat</A></B></TD>
<TD>Convert HBase tabular data into a format that is consumable by Map/Reduce.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.html" title="class in org.apache.hadoop.hbase.mapreduce">TableInputFormatBase</A></B></TD>
<TD>A base for <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableInputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableInputFormat</CODE></A>s.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableMapper.html" title="class in org.apache.hadoop.hbase.mapreduce">TableMapper&lt;KEYOUT,VALUEOUT&gt;</A></B></TD>
<TD>Extends the base <code>Mapper</code> class to add the required input key 
 and value classes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.html" title="class in org.apache.hadoop.hbase.mapreduce">TableMapReduceUtil</A></B></TD>
<TD>Utility for <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableMapper.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableMapper</CODE></A> and <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableReducer.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableReducer</CODE></A></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableOutputCommitter.html" title="class in org.apache.hadoop.hbase.mapreduce">TableOutputCommitter</A></B></TD>
<TD>Small committer class that does not do anything.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce">TableOutputFormat&lt;KEY&gt;</A></B></TD>
<TD>Convert Map/Reduce output and write it to an HBase table.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableOutputFormat.TableRecordWriter.html" title="class in org.apache.hadoop.hbase.mapreduce">TableOutputFormat.TableRecordWriter&lt;KEY&gt;</A></B></TD>
<TD>Writes the reducer output to an HBase table.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableReducer.html" title="class in org.apache.hadoop.hbase.mapreduce">TableReducer&lt;KEYIN,VALUEIN,KEYOUT&gt;</A></B></TD>
<TD>Extends the basic <code>Reducer</code> class to add the required key and
 value input/output classes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="15%"><B><A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableSplit.html" title="class in org.apache.hadoop.hbase.mapreduce">TableSplit</A></B></TD>
<TD>A table split corresponds to a key range (low, high).</TD>
</TR>
</TABLE>
&nbsp;

<P>
<A NAME="package_description"><!-- --></A><H2>
Package org.apache.hadoop.hbase.mapreduce Description
</H2>

<P>
Provides HBase <a href="http://wiki.apache.org/hadoop/HadoopMapReduce">MapReduce</a>
Input/OutputFormats, a table indexing MapReduce job, and utility

<h2>Table of Contents</h2>
<ul>
<li><a href="#classpath">HBase, MapReduce and the CLASSPATH</a></li>
<li><a href="#sink">HBase as MapReduce job data source and sink</a></li>
<li><a href="#bulk">Bulk Import writing HFiles directly</a></li>
<li><a href="#examples">Example Code</a></li>
</ul>

<h2><a name="classpath">HBase, MapReduce and the CLASSPATH</a></h2>

<p>MapReduce jobs deployed to a MapReduce cluster do not by default have access
to the HBase configuration under <code>$HBASE_CONF_DIR</code> nor to HBase classes.
You could add <code>hbase-site.xml</code> to $HADOOP_HOME/conf and add
hbase jars to the <code>$HADOOP_HOME/lib</code> and copy these
changes across your cluster but a cleaner means of adding hbase configuration
and classes to the cluster <code>CLASSPATH</code> is by uncommenting
<code>HADOOP_CLASSPATH</code> in <code>$HADOOP_HOME/conf/hadoop-env.sh</code>
adding hbase dependencies here.  For example, here is how you would amend
<code>hadoop-env.sh</code> adding the
built hbase jar, zookeeper (needed by hbase client), hbase conf, and the
<code>PerformanceEvaluation</code> class from the built hbase test jar to the
hadoop <code>CLASSPATH</code>:

<blockquote><pre># Extra Java CLASSPATH elements. Optional.
# export HADOOP_CLASSPATH=
export HADOOP_CLASSPATH=$HBASE_HOME/build/hbase-X.X.X.jar:$HBASE_HOME/build/hbase-X.X.X-test.jar:$HBASE_HOME/conf:${HBASE_HOME}/lib/zookeeper-X.X.X.jar</pre></blockquote>

<p>Expand <code>$HBASE_HOME</code> in the above appropriately to suit your
local environment.</p>

<p>After copying the above change around your cluster (and restarting), this is
how you would run the PerformanceEvaluation MR job to put up 4 clients (Presumes
a ready mapreduce cluster):

<blockquote><pre>$HADOOP_HOME/bin/hadoop org.apache.hadoop.hbase.PerformanceEvaluation sequentialWrite 4</pre></blockquote>
</p>

<p>Another possibility, if for example you do not have access to hadoop-env.sh or
are unable to restart the hadoop cluster, is bundling the hbase jars into a mapreduce
job jar adding it and its dependencies under the job jar <code>lib/</code>
directory and the hbase conf into the job jars top-level directory.
</a>

<h2><a name="sink">HBase as MapReduce job data source and sink</a></h2>

<p>HBase can be used as a data source, <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableInputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableInputFormat</CODE></A>,
and data sink, <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableOutputFormat</CODE></A>, for MapReduce jobs.
Writing MapReduce jobs that read or write HBase, you'll probably want to subclass
<A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableMapper.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableMapper</CODE></A> and/or
<A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableReducer.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableReducer</CODE></A>.  See the do-nothing
pass-through classes <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IdentityTableMapper.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>IdentityTableMapper</CODE></A> and
<A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/IdentityTableReducer.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>IdentityTableReducer</CODE></A> for basic usage.  For a more
involved example, see <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/RowCounter.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>RowCounter</CODE></A>
or review the <code>org.apache.hadoop.hbase.mapreduce.TestTableMapReduce</code> unit test.
</p>

<p>Running mapreduce jobs that have hbase as source or sink, you'll need to
specify source/sink table and column names in your configuration.</p>

<p>Reading from hbase, the TableInputFormat asks hbase for the list of
regions and makes a map-per-region or <code>mapred.map.tasks maps</code>,
whichever is smaller (If your job only has two maps, up mapred.map.tasks
to a number &gt; number of regions). Maps will run on the adjacent TaskTracker
if you are running a TaskTracer and RegionServer per node.
Writing, it may make sense to avoid the reduce step and write yourself back into
hbase from inside your map. You'd do this when your job does not need the sort
and collation that mapreduce does on the map emitted data; on insert,
hbase 'sorts' so there is no point double-sorting (and shuffling data around
your mapreduce cluster) unless you need to. If you do not need the reduce,
you might just have your map emit counts of records processed just so the
framework's report at the end of your job has meaning or set the number of
reduces to zero and use TableOutputFormat. See example code
below. If running the reduce step makes sense in your case, its usually better
to have lots of reducers so load is spread across the hbase cluster.</p>

<p>There is also a new hbase partitioner that will run as many reducers as
currently existing regions.  The 
<A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/HRegionPartitioner.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>HRegionPartitioner</CODE></A> is suitable
when your table is large and your upload is not such that it will greatly
alter the number of existing regions when done; otherwise use the default
partitioner.
</p>

<h2><a name="bulk">Bulk import writing HFiles directly</a></h2>
<p>If importing into a new table, its possible to by-pass the HBase API
and write your content directly to the filesystem properly formatted as
HBase data files (HFiles).  Your import will run faster, perhaps as much
as an order of magnitude faster if not more.
</p>
<p>You will need to write a MapReduce job.  The map task will know how to
pull from your data source.  Your reduce task will need to be hooked up to
<A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>HFileOutputFormat</CODE></A>.  It expects to receive a row id and a value.
The row id must be formatted as a <A HREF="../../../../../org/apache/hadoop/hbase/io/ImmutableBytesWritable.html" title="class in org.apache.hadoop.hbase.io"><CODE>ImmutableBytesWritable</CODE></A> and the
value as a <A HREF="../../../../../org/apache/hadoop/hbase/KeyValue.html" title="class in org.apache.hadoop.hbase"><CODE>KeyValue</CODE></A> (A KeyValue holds the value for a cell and
its coordinates; row/family/qualifier/timestamp, etc.).  Note that you must
specify a timestamp when you create the KeyValue in your map task
otherwise the KeyValue will be created with the default LATEST_TIMESTAMP (Long.MAX_VALUE).  
Use System.currentTimeMillis() if your data does not inherently bear a timestamp.
Your reduce task
will also need to emit the KeyValues in order.  See <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/KeyValueSortReducer.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>KeyValueSortReducer</CODE></A>
for an example reducer that emits KeyValues in order.
</p>
<p>Most importantly, you will also need to ensure that your MapReduce job
ensures a total ordering among all keys.  MapReduce by default distributes
keys among reducers using a Partitioner that hashes on the map task output
key: i.e. the reducer a key ends up in is by default determined as follows
<code> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks</code>.
Keys are sorted by the MapReduce framework before they are passed to the reducer
BUT the sort is scoped to the particular reducer.  Its not a global sort.
Given the default hash Partitioner, if the keys were 0-4 (inclusive), and you
had configured two reducers, reducer 0 would have get keys 0, 2 and 4 whereas
reducer 1 would get keys 1 and 3 (in order).  For your bulk import to work,
the keys need to be orderd so reducer 0 gets keys 0-2 and reducer 1 gets keys
3-4 (See TotalOrderPartitioner up in hadoop for more on what this means). 
To achieve total ordering, you will likely need to write a Partitioner
that is intimate with your tables key namespace and that knows how
to distribute keys among the reducers so a total order is maintained
(You need at least hadoop 0.20.1 setting your own Partitioner -- see MAPREDUCE-565).
</p>
<p>See org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat for an example that puts together
<A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/KeyValueSortReducer.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>KeyValueSortReducer</CODE></A> and <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/HFileOutputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>HFileOutputFormat</CODE></A>.</p>

<p>HFileOutputFormat writes HFiles.  When your MapReduce file finishes, in your
output directory you will have many HFiles.  Run the script <code>bin/loadtable.rb</code>
to move the files from the MapReduce output directory under hbase.  See head of script
for how to run it.  This script
also adds the new table data to the hbase catalog tables.  When the script completes,
on the next run of the hbase metascanner -- it usually runs every minute -- your
new table should be visible and populated.</p>

<h2><a name="examples">Example Code</a></h2>
<h3>Sample Row Counter</h3>
<p>See <A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/RowCounter.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>RowCounter</CODE></A>.  This job uses
<A HREF="../../../../../org/apache/hadoop/hbase/mapreduce/TableInputFormat.html" title="class in org.apache.hadoop.hbase.mapreduce"><CODE>TableInputFormat</CODE></A> and
does a count of all rows in specified table.
You should be able to run
it by doing: <code>% ./bin/hadoop jar hbase-X.X.X.jar</code>.  This will invoke
the hbase MapReduce Driver class.  Select 'rowcounter' from the choice of jobs
offered. This will emit rowcouner 'usage'.  Specify tablename, column to count
and output directory.  You may need to add the hbase conf directory to <code>$HADOOP_HOME/conf/hadoop-env.sh#HADOOP_CLASSPATH</code>
so the rowcounter gets pointed at the right hbase cluster (or, build a new jar
with an appropriate hbase-site.xml built into your job jar).
</p>
<P>

<P>
<DL>
</DL>
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Package</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-use.html"><FONT CLASS="NavBarFont1"><B>Use</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../org/apache/hadoop/hbase/mapred/package-summary.html"><B>PREV PACKAGE</B></A>&nbsp;
&nbsp;<A HREF="../../../../../org/apache/hadoop/hbase/master/package-summary.html"><B>NEXT PACKAGE</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../index.html?org/apache/hadoop/hbase/mapreduce/package-summary.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="package-summary.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2010 The Apache Software Foundation
</BODY>
</HTML>
